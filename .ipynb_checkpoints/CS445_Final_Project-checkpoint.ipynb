{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confused-staff",
   "metadata": {},
   "source": [
    "## Hand Gesture Recognition\n",
    "\n",
    "This notebook implements hand gesture recognition using OpenCV for the purpose of playing rock paper scissors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mediterranean-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-devon",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eleven-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlurredRegion(img, start, end, kernel=(7, 7)):\n",
    "    \"\"\"Get the rectangular region from the image corresponding to start and end points, convert to grayscale, and blur.\"\"\"\n",
    "    region = img[start[1]:end[1], start[0]:end[0]]\n",
    "    region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "    region = cv2.GaussianBlur(region, kernel, 0)\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tamil-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForegroundMask(img, bg, threshold=15):\n",
    "    \"\"\"Returns the foreground mask of an image given the background and a threshold.\"\"\"\n",
    "    diff = cv2.absdiff(bg.astype(np.uint8), img)\n",
    "    mask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHandContour(img):\n",
    "    \"\"\"Returns the contour corresponding to the hand from a masked image.\"\"\"\n",
    "    contours, hierarchy = cv2.findContours(img, cv2. RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # contour with maximum area should be the hand\n",
    "        return max(contours, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chicken-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizeGesture(cnt, thresh=30):\n",
    "    \"\"\"Determines whether a hand gesture corresponds to rock, paper, or scissors.\"\"\"\n",
    "    hull = cv2.convexHull(cnt, returnPoints=False)\n",
    "    try:\n",
    "        defects = cv2.convexityDefects(cnt, hull)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    # defects with an approx. distance to farthest point greater than the threshold are considered to correspond to the space between figners\n",
    "    if defects is not None:\n",
    "        n = 0 # number of spaces between fingers\n",
    "        for i in range(defects.shape[0]):\n",
    "            s, e, f, d = defects[i, 0]\n",
    "            if d / 256.0 > thresh:\n",
    "                n += 1\n",
    "    \n",
    "        if n >= 4: # should really be n == 4, but n >= 4 can be less finicky for paper detection\n",
    "            return \"paper\"\n",
    "        elif n == 1:\n",
    "            return \"scissors\"\n",
    "        elif n == 0:\n",
    "            return \"rock\" # cannot actually distinguish between 1 and 0 fingers held up\n",
    "        else:\n",
    "            return\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-consumer",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "* `start_point` and `end_point` are the top-left and bottom-right x-y coordinates for the bounding box corresponding to the region of the video where your hand will be placed. This region needs to remain stationary for 30 frames at the start of code execution to initialize a background model for the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjusted-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates for rectangle of hand region\n",
    "start_point = (10, 10)\n",
    "end_point = (310, 310)\n",
    "#start_point = (250, 250)\n",
    "#end_point = (550, 550)\n",
    "\n",
    "# alpha for running average background model\n",
    "alpha = 0.5\n",
    "\n",
    "# kernel for mophological transformations\n",
    "kernel = np.ones((5, 5), np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-malaysia",
   "metadata": {},
   "source": [
    "## Recognize gestures from livestream\n",
    "Let the background model initialize by keeping the scene in the bounding box region still for 30 frames. Placing your hand in the bounding box afterwards should output a text prediction of the gesture (rock, paper, or scissors). The hand contour is displayed in red and the convex hull is displayed in green. An additional window showing the foreground mask for the hand is also displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "destroyed-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture frames from camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# initialize background\n",
    "_, bg = capture.read()\n",
    "bg = imutils.resize(bg, width=800)\n",
    "bg = np.float32(bg)\n",
    "bg = getBlurredRegion(bg, start_point, end_point)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    _, frame = capture.read()\n",
    "    \n",
    "    # resize frame\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    \n",
    "    # get hand region, convert to grayscale, and blur\n",
    "    region = getBlurredRegion(frame, start_point, end_point)\n",
    "    \n",
    "    # update background model if frame_count < 30 otherwise get foreground mask \n",
    "    if frame_count < 30:\n",
    "        cv2.accumulateWeighted(region, bg, alpha)\n",
    "    else:\n",
    "        fg_mask = getForegroundMask(region, bg)\n",
    "        \n",
    "        # apply morphological transformations to remove holes in foregound mask\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # get hand contour and draw\n",
    "        cnt = getHandContour(fg_mask)\n",
    "        if cnt is not None:\n",
    "            cv2.drawContours(frame, [cnt + start_point], -1, (0, 0, 255), 2)\n",
    "            \n",
    "            # get convex hull and draw\n",
    "            hull = cv2.convexHull(cnt)\n",
    "            cv2.drawContours(frame, [hull + start_point], -1, (0, 255, 0), 2)\n",
    "            \n",
    "            # detect gesture and display text\n",
    "            gesture = recognizeGesture(cnt)\n",
    "            if gesture is not None:\n",
    "                cv2.putText(frame, gesture, (end_point[0], start_point[1] + 20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "            \n",
    "            \n",
    "        # display mask\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "    \n",
    "    # draw rectangle for hand region\n",
    "    cv2.rectangle(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "    \n",
    "    # display frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    keypress = cv2.waitKey(1)\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-wisconsin",
   "metadata": {},
   "source": [
    "## Play rock paper scissors\n",
    "With another person (or by yourself!), make the appropriate gestures in the two bounding boxes after the background models have initialized. The gestures of each person and the winner will be displayed on screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parental-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineWinner(gesture_b, gesture_g):\n",
    "    \"\"\"Determines the winner of rock paper scissors from gestures.\"\"\"\n",
    "    if ((gesture_b == \"paper\" and gesture_g == \"rock\") or \n",
    "        (gesture_b == \"rock\" and gesture_g == \"scissors\") or \n",
    "        (gesture_b == \"scissors\" and gesture_g == \"paper\")):\n",
    "        return \"blue\"\n",
    "    elif ((gesture_g == \"paper\" and gesture_b == \"rock\") or \n",
    "        (gesture_g == \"rock\" and gesture_b == \"scissors\") or \n",
    "        (gesture_g == \"scissors\" and gesture_b == \"paper\")):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"draw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conservative-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates for rectangles of hand regions for both players\n",
    "start_point_b = (10, 10)\n",
    "end_point_b = (260, 260)\n",
    "start_point_g = (10, 270)\n",
    "end_point_g = (260, 520)\n",
    "\n",
    "# alpha for running average background model\n",
    "alpha = 0.5\n",
    "\n",
    "# kernel for mophological transformations\n",
    "kernel = np.ones((5, 5), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "academic-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture frames from camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# initialize backgrounds\n",
    "_, bg = capture.read()\n",
    "bg = imutils.resize(bg, width=800)\n",
    "bg = np.float32(bg)\n",
    "bg_b = getBlurredRegion(bg, start_point_b, end_point_b)\n",
    "bg_g = getBlurredRegion(bg, start_point_g, end_point_g)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    _, frame = capture.read()\n",
    "    \n",
    "    # resize frame\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    \n",
    "    # get hand regions, convert to grayscale, and blur\n",
    "    region_b = getBlurredRegion(frame, start_point_b, end_point_b)\n",
    "    region_g = getBlurredRegion(frame, start_point_g, end_point_g)\n",
    "    \n",
    "    # update background models if frame_count < 30 otherwise get foreground masks \n",
    "    if frame_count < 30:\n",
    "        cv2.accumulateWeighted(region_b, bg_b, alpha)\n",
    "        cv2.accumulateWeighted(region_g, bg_g, alpha)\n",
    "    else:\n",
    "        fg_mask_b = getForegroundMask(region_b, bg_b)\n",
    "        fg_mask_g = getForegroundMask(region_g, bg_g)\n",
    "        \n",
    "        # apply morphological transformations to remove holes in foregound masks\n",
    "        fg_mask_b = cv2.morphologyEx(fg_mask_b, cv2.MORPH_CLOSE, kernel)\n",
    "        fg_mask_g = cv2.morphologyEx(fg_mask_g, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # get hand contours\n",
    "        cnt_b = getHandContour(fg_mask_b)\n",
    "        cnt_g = getHandContour(fg_mask_g)\n",
    "        gesture_b, gesture_g = None, None\n",
    "        if cnt_b is not None:\n",
    "            cv2.drawContours(frame, [cnt_b + start_point_b], -1, (0, 0, 255), 2)\n",
    "            # detect gesture and display text\n",
    "            gesture_b = recognizeGesture(cnt_b)\n",
    "            if gesture_b is not None:\n",
    "                cv2.putText(frame, gesture_b, (start_point_b[0], end_point_b[1]), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "        if cnt_g is not None:\n",
    "            cv2.drawContours(frame, [cnt_g + start_point_g], -1, (0, 0, 255), 2)\n",
    "            # detect gesture and display text\n",
    "            gesture_g = recognizeGesture(cnt_g)\n",
    "            if gesture_g is not None:\n",
    "                cv2.putText(frame, gesture_g, (start_point_g[0], end_point_g[1]), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "        if gesture_b is not None and gesture_g is not None:\n",
    "            # determine winner and display\n",
    "            winner = determineWinner(gesture_b, gesture_g)\n",
    "            if winner == \"blue\":\n",
    "                cv2.putText(frame, \"blue wins!\", (320, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "            elif winner == \"green\":\n",
    "                cv2.putText(frame, \"green wins!\", (320, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "            else:\n",
    "                cv2.putText(frame, \"draw!\", (320, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4)\n",
    "            \n",
    "    # draw rectangles for hand regions\n",
    "    cv2.rectangle(frame, start_point_b, end_point_b, (255, 0, 0), 2)\n",
    "    cv2.rectangle(frame, start_point_g, end_point_g, (0, 255, 0), 2)\n",
    "    \n",
    "    # display frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    keypress = cv2.waitKey(1)\n",
    "    if keypress == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-termination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
